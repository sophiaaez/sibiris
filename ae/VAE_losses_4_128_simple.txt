trained with learning rate 0.0001, batch size 8, planned epochs 1000 but only took 150 epochs.training_losses
128.34703063964844
124.93395233154297
124.71755981445312
125.09906768798828
124.72250366210938
124.7516098022461
124.83757019042969
124.73058319091797
124.67969512939453
124.54730224609375
124.61206817626953
124.76206970214844
124.67225646972656
124.60578918457031
124.56785583496094
124.68852996826172
124.4396743774414
124.57012939453125
124.40632629394531
124.66262817382812
124.59821319580078
124.62728881835938
124.45149230957031
124.56011199951172
124.49999237060547
124.56610107421875
124.46685791015625
124.45416259765625
124.69869232177734
124.54806518554688
124.7032699584961
124.35063934326172
124.58788299560547
124.3695297241211
124.5692367553711
124.53402709960938
124.51009368896484
124.6015853881836
124.49866485595703
124.59611511230469
124.61075592041016
124.58419799804688
124.55220031738281
124.47737121582031
124.55072021484375
124.47893524169922
124.44876861572266
124.32637023925781
124.5797119140625
124.47966003417969
124.52645111083984
124.48521423339844
124.56185913085938
124.45037841796875
124.43614196777344
124.32719421386719
124.43193817138672
124.42855072021484
124.47234344482422
124.43938446044922
124.49835968017578
124.32813262939453
124.36520385742188
124.38838958740234
124.42407989501953
124.55706024169922
124.56608581542969
124.42364501953125
124.51805114746094
124.4420394897461
124.45758056640625
124.57941436767578
124.53079986572266
124.29969024658203
124.52924346923828
124.62545013427734
124.61749267578125
124.5139389038086
124.4436264038086
124.36647033691406
124.41410827636719
124.5801773071289
124.5440902709961
124.24832153320312
124.42461395263672
124.36151123046875
124.32402038574219
124.4330825805664
124.382568359375
124.34046173095703
124.4869384765625
124.47634887695312
124.64723205566406
124.47938537597656
124.51879119873047
124.39152526855469
124.35105895996094
124.46670532226562
124.33738708496094
124.26394653320312
124.45175170898438
124.46247100830078
124.5227279663086
124.4463119506836
124.57685852050781
124.55006408691406
124.32386779785156
124.52322387695312
124.43678283691406
124.40692138671875
124.38230895996094
124.30433654785156
124.45889282226562
124.28006744384766
124.47406005859375
124.45813751220703
124.34070587158203
124.61714935302734
124.34210968017578
124.527099609375
124.47626495361328
124.45899200439453
124.3980712890625
124.2721939086914
124.46757507324219
124.54505920410156
124.37647247314453
124.3497314453125
124.7413330078125
124.61863708496094
124.36541748046875
124.54121398925781
124.40518188476562
124.5379638671875
124.44599914550781
124.2725601196289
124.40262603759766
124.32283020019531
124.35281372070312
124.54815673828125
124.42000579833984
124.57308197021484
124.50260925292969
124.4339599609375
124.36373901367188
124.22135162353516
124.47303009033203
124.49478149414062
124.52174377441406
124.3896255493164
124.56935119628906
validation_losses
62.90122985839844
62.70633316040039
62.76179885864258
62.64037322998047
62.76438522338867
62.499752044677734
62.4925651550293
62.56987762451172
62.657875061035156
62.62156677246094
62.563819885253906
62.65937042236328
62.663047790527344
62.625885009765625
62.60554504394531
62.54725646972656
