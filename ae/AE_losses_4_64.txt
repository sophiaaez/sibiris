trained with learning rate 0.0001, batch size 4, planned epochs 1000 but only took 179 epochs.training_losses
241.17062377929688
234.70655822753906
234.04962158203125
233.70535278320312
233.52581787109375
233.42190551757812
233.14785766601562
233.32150268554688
233.01878356933594
233.0769500732422
232.81277465820312
232.87777709960938
232.8825225830078
232.70864868164062
232.65005493164062
232.6439971923828
232.6511688232422
232.56199645996094
232.52523803710938
232.48684692382812
232.6365203857422
232.44723510742188
232.45928955078125
232.41709899902344
232.37860107421875
232.37847900390625
232.25640869140625
232.28036499023438
232.36575317382812
232.2641143798828
232.24484252929688
232.23658752441406
232.18453979492188
232.26124572753906
232.14486694335938
232.16758728027344
232.14041137695312
232.0763702392578
232.09327697753906
232.11289978027344
232.03123474121094
232.02394104003906
232.05624389648438
232.01747131347656
232.04640197753906
232.0266876220703
231.94981384277344
231.93038940429688
232.16514587402344
231.93075561523438
232.01913452148438
231.93028259277344
231.926513671875
232.05136108398438
231.94479370117188
231.87486267089844
231.872802734375
231.86582946777344
231.84324645996094
231.84628295898438
231.80569458007812
231.83436584472656
231.83865356445312
231.8301239013672
231.79098510742188
231.8436737060547
231.87208557128906
231.81504821777344
231.79322814941406
231.7045135498047
231.7519989013672
231.71389770507812
231.8042755126953
231.68394470214844
231.6864471435547
231.71124267578125
231.6650390625
231.7145538330078
231.627197265625
231.69784545898438
231.65185546875
231.6793670654297
231.6695098876953
231.69696044921875
231.63180541992188
231.6847381591797
231.6017608642578
231.63677978515625
231.57154846191406
231.61351013183594
231.60594177246094
231.58819580078125
231.65872192382812
231.56387329101562
231.6548309326172
231.60284423828125
231.55218505859375
231.59228515625
231.5708770751953
231.60073852539062
231.58599853515625
231.50758361816406
231.52899169921875
231.50003051757812
231.52984619140625
231.54574584960938
231.55433654785156
231.59750366210938
231.5198516845703
231.5199432373047
231.51942443847656
231.48348999023438
231.53109741210938
231.50808715820312
231.4826202392578
231.58619689941406
231.52667236328125
231.4822235107422
231.55938720703125
231.44239807128906
231.44216918945312
231.54576110839844
231.48330688476562
231.45570373535156
231.43353271484375
231.4237060546875
231.44747924804688
231.48069763183594
231.41632080078125
231.46694946289062
231.4073486328125
231.47344970703125
231.52732849121094
231.41554260253906
231.40159606933594
231.45028686523438
231.39559936523438
231.48171997070312
231.4025115966797
231.39132690429688
231.3936004638672
231.48095703125
231.3542022705078
231.38211059570312
231.392333984375
231.38063049316406
231.39157104492188
231.41734313964844
231.35400390625
231.43385314941406
231.3487548828125
231.42494201660156
231.40658569335938
231.37103271484375
231.33680725097656
231.39190673828125
231.3480987548828
231.32801818847656
231.3540802001953
231.33465576171875
231.37741088867188
231.3271942138672
231.40447998046875
231.37005615234375
231.31201171875
231.28317260742188
231.32144165039062
231.33169555664062
231.3318328857422
231.3361358642578
231.35020446777344
231.2932586669922
231.3400115966797
231.33937072753906
231.29339599609375
231.2616729736328
231.23866271972656
231.30738830566406
231.30442810058594
231.38388061523438
validation_losses
118.34013366699219
117.0655746459961
116.93769836425781
116.78662872314453
116.70677947998047
116.73407745361328
116.62794494628906
116.60685729980469
116.4921646118164
116.63235473632812
116.54094696044922
116.47450256347656
116.61451721191406
116.60154724121094
116.5867691040039
116.54039001464844
116.54495239257812
116.52753448486328
116.56832122802734
