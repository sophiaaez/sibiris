trained with learning rate 0.0001, batch size 8, planned epochs 1000 but only took 130 epochs.training_losses
1034.538330078125
1027.718505859375
1027.31982421875
1027.33740234375
1027.2427978515625
1027.2672119140625
1027.1492919921875
1027.003662109375
1027.0164794921875
1026.923828125
1026.8839111328125
1026.87744140625
1026.8076171875
1026.78955078125
1026.759765625
1026.7587890625
1026.7371826171875
1026.7528076171875
1026.7479248046875
1026.7076416015625
1026.6551513671875
1026.71435546875
1026.7066650390625
1026.6884765625
1026.6580810546875
1026.6729736328125
1026.6236572265625
1026.5848388671875
1026.6158447265625
1026.6697998046875
1026.648193359375
1026.6031494140625
1026.6187744140625
1026.59619140625
1026.52392578125
1026.552001953125
1026.6484375
1026.6116943359375
1026.528076171875
1026.62451171875
1026.572021484375
1026.5555419921875
1026.5518798828125
1026.5648193359375
1026.5760498046875
1026.54833984375
1026.56982421875
1026.5821533203125
1026.528564453125
1026.5709228515625
1026.525146484375
1026.5447998046875
1026.578125
1026.497802734375
1026.5762939453125
1026.50927734375
1026.5220947265625
1026.5362548828125
1026.53125
1026.5457763671875
1026.5283203125
1026.5528564453125
1026.5267333984375
1026.55029296875
1026.5462646484375
1026.47265625
1026.533935546875
1026.53369140625
1026.5908203125
1026.5111083984375
1026.511962890625
1026.5281982421875
1026.51318359375
1026.4759521484375
1026.521484375
1026.521728515625
1026.5274658203125
1026.542236328125
1026.515869140625
1026.5142822265625
1026.5157470703125
1026.515869140625
1026.4715576171875
1026.5418701171875
1026.5068359375
1026.47119140625
1026.5391845703125
1026.4849853515625
1026.4857177734375
1026.484130859375
1026.500244140625
1026.4736328125
1026.5218505859375
1026.504150390625
1026.484130859375
1026.52392578125
1026.4801025390625
1026.4605712890625
1026.5135498046875
1026.480224609375
1026.474609375
1026.4832763671875
1026.5025634765625
1026.4525146484375
1026.480224609375
1026.48486328125
1026.50732421875
1026.5054931640625
1026.48828125
1026.501220703125
1026.5013427734375
1026.490234375
1026.49169921875
1026.4642333984375
1026.51025390625
1026.46875
1026.5068359375
1026.4586181640625
1026.4884033203125
1026.4664306640625
1026.472900390625
1026.465087890625
1026.4940185546875
1026.452392578125
1026.501220703125
1026.4810791015625
1026.5006103515625
1026.470703125
1026.4683837890625
1026.4644775390625
validation_losses
514.3212280273438
513.7660522460938
513.6647338867188
513.5621948242188
513.5435791015625
513.6237182617188
513.6311645507812
513.5974731445312
513.5836181640625
513.5525512695312
513.599609375
513.5593872070312
513.5484008789062
513.538818359375
