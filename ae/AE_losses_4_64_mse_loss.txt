trained with learning rate 0.0001, batch size 8, planned epochs 1000 but only took 99 epochs.training_losses
488.9342956542969
475.2726135253906
473.6256408691406
473.6993103027344
472.9808044433594
472.61187744140625
471.8980407714844
471.79248046875
472.28057861328125
471.6363525390625
471.3524169921875
471.75927734375
472.87762451171875
471.957763671875
472.0758972167969
471.904296875
472.6739807128906
471.6462707519531
474.5159912109375
471.7933044433594
471.4822692871094
471.4481201171875
470.9945068359375
471.3415222167969
471.8643493652344
467.2893981933594
467.4708557128906
467.4047546386719
467.49609375
468.1218566894531
471.7336730957031
469.5970764160156
468.1768493652344
467.713134765625
467.4474182128906
467.2410888671875
467.1733093261719
466.9758605957031
466.842041015625
467.3021545410156
467.1442565917969
466.9169921875
467.0484313964844
466.82403564453125
466.6217041015625
466.3542175292969
466.9016418457031
466.9560852050781
466.6900329589844
466.4476318359375
466.66119384765625
466.3876647949219
466.34881591796875
467.0425720214844
466.2663269042969
466.3639831542969
466.51885986328125
466.38165283203125
466.8604431152344
466.3135986328125
466.53607177734375
466.6072692871094
466.2232360839844
465.8782958984375
466.1283264160156
466.5642395019531
466.23089599609375
466.4686279296875
465.87567138671875
466.4189758300781
466.24285888671875
466.0329895019531
466.0624694824219
466.2145080566406
465.8484802246094
466.299072265625
466.17138671875
466.2034606933594
466.1570129394531
466.1866760253906
466.6810607910156
465.8313903808594
465.95880126953125
465.69866943359375
465.58538818359375
465.6297912597656
465.8635559082031
466.20367431640625
465.6793518066406
465.79071044921875
465.9151916503906
466.0968017578125
465.7402648925781
465.86785888671875
465.52203369140625
465.55828857421875
465.89373779296875
465.4881286621094
465.4958190917969
466.0204162597656
siamese_losses
194.7814483642578
149.28472900390625
111.31668853759766
85.55741882324219
72.95719909667969
65.95008087158203
63.74277114868164
61.92176818847656
62.04423522949219
62.501380920410156
59.55244827270508
58.87611770629883
57.89450454711914
55.15615463256836
53.63581085205078
49.202213287353516
51.712162017822266
46.18694305419922
48.767147064208984
41.4724235534668
38.25956726074219
34.48487854003906
32.64646530151367
28.401840209960938
31.877805709838867
25.414947509765625
22.428707122802734
20.478673934936523
22.70275115966797
24.52634048461914
25.628904342651367
22.383342742919922
17.25541114807129
14.550740242004395
15.110034942626953
15.201892852783203
13.728742599487305
14.986396789550781
11.09838581085205
11.812398910522461
11.797237396240234
12.64460277557373
10.668784141540527
10.061814308166504
10.681415557861328
9.638102531433105
11.45753288269043
9.864418983459473
9.224111557006836
7.676935195922852
8.529946327209473
8.707701683044434
7.204875469207764
9.682132720947266
6.3229451179504395
6.481662750244141
7.066499710083008
6.622834205627441
5.571110725402832
5.966383457183838
7.995125770568848
9.017302513122559
6.866461753845215
4.293465614318848
4.771639347076416
5.865960121154785
7.564490795135498
7.687819480895996
3.6051506996154785
6.110684871673584
5.198142051696777
6.143674373626709
5.27856969833374
6.051301956176758
5.432981014251709
5.403329372406006
4.681572437286377
5.112297534942627
5.27246618270874
5.1224775314331055
5.8659539222717285
4.891660213470459
5.081736087799072
4.284664154052734
3.2241880893707275
3.8587450981140137
4.461345672607422
4.774928569793701
4.528234004974365
3.4015631675720215
4.585163593292236
5.209655284881592
3.630324125289917
4.228714466094971
3.9164116382598877
3.3227288722991943
4.532753944396973
3.5580697059631348
2.5696496963500977
3.6722211837768555
validation_losses
237.2376708984375
235.18206787109375
235.36912536621094
234.9161376953125
233.82200622558594
232.4467010498047
232.38580322265625
232.66873168945312
232.53427124023438
232.59190368652344
233.7240447998047
