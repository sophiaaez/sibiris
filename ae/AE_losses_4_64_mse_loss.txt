trained with learning rate 0.0001, batch size 8, planned epochs 1000 but only took 59 epochs.training_losses
130.2489776611328
129.55557250976562
128.6021270751953
129.13925170898438
129.08148193359375
129.07986450195312
129.0729522705078
129.07073974609375
129.05825805664062
129.04812622070312
129.0434112548828
129.03631591796875
129.03521728515625
129.03155517578125
129.02957153320312
129.0270233154297
129.02584838867188
129.0237579345703
129.0211944580078
129.01837158203125
129.01766967773438
129.016845703125
129.01480102539062
129.01303100585938
129.0110626220703
129.00987243652344
129.00828552246094
129.00698852539062
129.0062255859375
129.00379943847656
129.00282287597656
129.0034942626953
129.0028076171875
128.99835205078125
128.99813842773438
128.99696350097656
128.9933319091797
128.99082946777344
128.98947143554688
128.98646545410156
128.98526000976562
128.9818572998047
128.98023986816406
128.97865295410156
128.97698974609375
128.97544860839844
128.9747314453125
128.97384643554688
128.97409057617188
128.9735870361328
128.9718017578125
128.97120666503906
128.9712371826172
128.96865844726562
128.96803283691406
128.96763610839844
128.97007751464844
128.9743194580078
128.9669647216797
128.96551513671875
siamese_losses
51.46570587158203
47.957672119140625
44.86498260498047
40.84223937988281
37.18424987792969
33.29361343383789
29.265993118286133
25.31825065612793
21.719127655029297
18.614578247070312
16.081756591796875
14.247550010681152
12.763230323791504
11.72077465057373
10.913591384887695
10.339422225952148
9.902046203613281
9.613221168518066
9.390953063964844
9.197416305541992
9.052634239196777
8.940388679504395
8.845121383666992
8.83560562133789
8.771441459655762
8.696565628051758
8.68293285369873
8.652484893798828
8.651681900024414
8.62975025177002
8.638932228088379
8.594124794006348
8.605064392089844
8.605562210083008
8.581974983215332
8.566373825073242
8.591167449951172
8.582833290100098
8.561248779296875
8.581366539001465
8.599940299987793
8.570052146911621
8.595267295837402
8.579967498779297
8.583868980407715
8.576079368591309
8.573786735534668
8.609609603881836
8.579538345336914
8.578547477722168
8.585539817810059
8.551446914672852
8.615340232849121
8.600200653076172
8.556452751159668
8.562491416931152
8.596372604370117
8.563803672790527
8.582128524780273
8.606678009033203
validation_losses
65.0843734741211
64.51187133789062
64.50090026855469
64.49282836914062
64.48652648925781
64.48503875732422
64.48768615722656
